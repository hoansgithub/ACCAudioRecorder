# ACCAudioRecorder

A production-ready, actor-isolated audio recorder built with **AVAudioEngine** and **Accelerate** framework. Designed with a flexible broadcast-based AsyncStream architecture for maximum performance and versatility.

## ‚ú® Features

### Core Capabilities
- ‚úÖ **Broadcast-based AsyncStream** - Multiple subscribers to same recording session
- ‚úÖ **AVAudioEngine-based** - Full control over audio pipeline
- ‚úÖ **Actor-isolated** - Thread-safe with Swift Concurrency
- ‚úÖ **Accelerate-optimized** - 10-100x faster audio processing with SIMD
- ‚úÖ **Real-time buffer access** - Process audio as it's being recorded
- ‚úÖ **Background recording** - Continues when app is backgrounded
- ‚úÖ **Pause/Resume** - Full recording session control
- ‚úÖ **Auto-stop** - Optional max duration limit

### Streams & Monitoring
- üéµ **Audio Buffer Stream** - Broadcast-based AsyncStream of raw audio data (Float32)
- üìä **Audio Level History Stream** - Real-time audio level monitoring with 100-sample history
- üéôÔ∏è **Recording State Stream** - Monitor recording state changes (recording/paused/duration)

### Audio Session Management
- ‚òéÔ∏è **Interruption handling** - Automatic pause/resume for phone calls, Siri, etc.
- üéß **Bluetooth support** - Works with Bluetooth headsets and speakers
- üîá **Session management** - Proper audio session lifecycle

---

## üì¶ Installation

### Swift Package Manager

Add ACCAudioRecorder to your project's `Package.swift`:

```swift
dependencies: [
    .package(url: "https://github.com/hoansgithub/ACCAudioRecorder.git", from: "1.0.0")
]
```

Then add it to your target dependencies:

```swift
.target(
    name: "YourTarget",
    dependencies: [
        .product(name: "ACCAudioRecorder", package: "ACCAudioRecorder")
    ]
)
```

#### Xcode

1. In Xcode, go to **File > Add Package Dependencies...**
2. Enter the repository URL: `https://github.com/hoansgithub/ACCAudioRecorder.git`
3. Select the version rule (e.g., "Up to Next Major Version" from `1.0.0`)
4. Click **Add Package**
5. Select your target and click **Add Package**

---

## üöÄ Quick Start

### Basic Recording Setup

```swift
import ACCAudioRecorder

let recorder = ACCAudioRecorder()

// Start recording and get streams
let streams = try await recorder.startRecording()

// Process audio buffers
Task {
    for await buffer in streams.buffers {
        // Save to file, transcribe, etc.
    }
}

// Monitor audio levels
Task {
    for await history in streams.audioLevelHistory {
        let currentLevel = history.last ?? -160.0
        updateUI(level: currentLevel)
    }
}

// Monitor recording state
Task {
    for await state in streams.state {
        updateUI(
            isRecording: state.isRecording,
            isPaused: state.isPaused,
            duration: state.currentDuration ?? 0
        )
    }
}

// Stop recording after 5 seconds
try await Task.sleep(for: .seconds(5))
await recorder.finishRecording()
```

### Multiple Views Observing Same Recording

```swift
// ViewModel creates recorder
class RecorderViewModel {
    let recorder = ACCAudioRecorder()
}

// View 1: Waveform visualization
Task {
    if let streams = await recorder.getCurrentStreams() {
        for await history in streams.audioLevelHistory {
            updateWaveform(history)
        }
    }
}

// View 2: Timer display
Task {
    if let streams = await recorder.getCurrentStreams() {
        for await state in streams.state {
            updateTimer(state.currentDuration ?? 0)
        }
    }
}
```

---

## üì± Requirements

- iOS 16.0+
- Swift 6.0+
- Xcode 16.0+

**Note**: ACCAudioRecorder is iOS-only due to AVAudioSession APIs.

### Info.plist Configuration

Add microphone permission:

```xml
<key>NSMicrophoneUsageDescription</key>
<string>We need access to your microphone to record audio.</string>
```

For background recording, add:

```xml
<key>UIBackgroundModes</key>
<array>
    <string>audio</string>
</array>
```

---

## üìñ API Reference

### Configuration

```swift
let config = ACCAudioRecorder.Configuration(
    sampleRate: 44100,          // CD quality (default)
    channelCount: 1,            // Mono (default)
    bufferSize: 4096,           // Frames per buffer (default)
    audioSessionMode: .default  // Audio session mode (default)
)

let recorder = ACCAudioRecorder(configuration: config)
```

#### Audio Session Modes

Choose the appropriate mode for your use case:

| Mode | Best For | Quality | Use Case |
|------|----------|---------|----------|
| `.default` | General recording | Good | General purpose |
| `.measurement` | Music, instruments | Highest | High-fidelity recording |
| `.voiceChat` | Voice notes, calls | Voice-optimized | Speech/voice memos |
| `.videoRecording` | Video with audio | Balanced | Recording with video |
| `.spokenAudio` | Podcasts, audiobooks | Voice-optimized | Long-form speech |

**Examples:**

```swift
// For voice notes
let voiceConfig = ACCAudioRecorder.Configuration(
    audioSessionMode: .voiceChat
)

// For music recording
let musicConfig = ACCAudioRecorder.Configuration(
    sampleRate: 48000,
    audioSessionMode: .measurement
)
```

### Recording Control

```swift
// Start recording - returns RecordingStreams
let streams = try await recorder.startRecording()

// Get streams for existing recording (reconnection)
if let streams = await recorder.getCurrentStreams() {
    // Observe streams
}

// Finish recording
await recorder.finishRecording()

// Pause recording
await recorder.pauseRecording()

// Resume recording
try await recorder.resumeRecording()

// Discard recording
await recorder.discardRecording()
```

### Time Limit

```swift
// Set maximum recording duration
await recorder.setTimeLimit(maxDuration: 3600) {
    print("Recording stopped - time limit reached")
}

// Clear time limit
await recorder.clearTimeLimit()
```

### Interruption Handling

```swift
await recorder.setOnUnrecoverableInterruption {
    print("Recording interrupted and discarded")
    // Update UI, restart recording, etc.
}
```

### Recording Streams

```swift
public struct RecordingStreams: Sendable {
    public let buffers: AsyncStream<AudioBufferData>
    public let audioLevelHistory: AsyncStream<[Float]>  // Last 100 samples
    public let state: AsyncStream<RecordingState>
}
```

### Audio Buffer Data

```swift
public struct AudioBufferData: Sendable {
    public let data: Data                        // Raw Float32 samples
    public let frameLength: AVAudioFrameCount    // Number of frames
    public let sampleRate: Double                // Sample rate
    public let channelCount: AVAudioChannelCount // Channel count
    public let timestamp: TimeInterval           // Time since start
    public let hostTime: UInt64                  // AVAudioTime host time

    public func toFloatArray() -> [Float]?
}
```

### Recording State

```swift
public struct RecordingState: Sendable {
    public let isRecording: Bool
    public let isPaused: Bool
    public let currentDuration: TimeInterval?
}
```

---

## üí° Examples

### Example 1: Save to File

```swift
actor AudioFileWriter {
    private var audioFile: AVAudioFile?

    init(fileURL: URL, sampleRate: Double = 44100, channelCount: UInt32 = 1) throws {
        let format = AVAudioFormat(
            commonFormat: .pcmFormatFloat32,
            sampleRate: sampleRate,
            channels: channelCount,
            interleaved: false
        )!

        self.audioFile = try AVAudioFile(
            forWriting: fileURL,
            settings: format.settings
        )
    }

    func write(_ bufferData: AudioBufferData) throws {
        // Convert AudioBufferData to AVAudioPCMBuffer and write
    }

    func close() {
        audioFile = nil
    }
}

// Usage
let recorder = ACCAudioRecorder()
let streams = try await recorder.startRecording()

Task {
    let writer = try AudioFileWriter(fileURL: fileURL)
    for await buffer in streams.buffers {
        try writer.write(buffer)
    }
    writer.close()
}

try await Task.sleep(for: .seconds(5))
await recorder.finishRecording()
```

### Example 2: Real-Time Transcription

```swift
let streams = try await recorder.startRecording()

Task {
    for await buffer in streams.buffers {
        await transcriptionService.process(buffer)
    }
}

try await Task.sleep(for: .seconds(30))
await recorder.finishRecording()
```

### Example 3: SwiftUI Integration

```swift
@MainActor
class RecordingViewModel: ObservableObject {
    @Published var isRecording = false
    @Published var duration: TimeInterval = 0
    @Published var audioLevel: Float = -160

    private let recorder = ACCAudioRecorder()
    private var bufferTask: Task<Void, Never>?
    private var historyTask: Task<Void, Never>?
    private var stateTask: Task<Void, Never>?

    init() {
        Task {
            await recorder.setOnUnrecoverableInterruption { [weak self] in
                await MainActor.run {
                    self?.isRecording = false
                }
            }
        }
    }

    func startRecording() async throws {
        let streams = try await recorder.startRecording()

        // Process buffers
        bufferTask = Task {
            let writer = try? AudioFileWriter(fileURL: getFileURL())
            for await buffer in streams.buffers {
                try? writer?.write(buffer)
            }
            writer?.close()
        }

        // Monitor audio levels
        historyTask = Task {
            for await history in streams.audioLevelHistory {
                await MainActor.run {
                    self.audioLevel = history.last ?? -160.0
                }
            }
        }

        // Monitor state
        stateTask = Task {
            for await state in streams.state {
                await MainActor.run {
                    self.isRecording = state.isRecording
                    self.duration = state.currentDuration ?? 0
                }
            }
        }
    }

    func stopRecording() async {
        await recorder.finishRecording()
        bufferTask?.cancel()
        historyTask?.cancel()
        stateTask?.cancel()
    }

    deinit {
        bufferTask?.cancel()
        historyTask?.cancel()
        stateTask?.cancel()
    }
}
```

---

## üì± Interruption Handling

### Understanding Interruptions

iOS audio interruptions occur when another app or system event needs audio access. `ACCAudioRecorder` automatically handles these scenarios:

| Interruption Type | Automatic Action | Callback Triggered |
|-------------------|------------------|-------------------|
| **Phone call (regular)** | Pause ‚Üí Resume when call ends | ‚ùå No |
| **Phone call (emergency)** | Pause ‚Üí Discard (can't resume) | ‚úÖ Yes |
| **FaceTime call** | Pause ‚Üí Discard (can't resume) | ‚úÖ Yes |
| **Siri (quick)** | Pause ‚Üí Resume after Siri | ‚ùå No |
| **Siri (long)** | Pause ‚Üí Discard (timeout) | ‚úÖ Yes |
| **Alarm/Timer** | Pause ‚Üí Resume after alarm | ‚ùå No |
| **Bluetooth disconnect** | Pause ‚Üí Discard | ‚úÖ Yes |
| **Audio session failure** | Discard immediately | ‚úÖ Yes |

### When `onUnrecoverableInterruption` is Called

The callback is triggered in these scenarios:

1. **No interruption options** - System didn't provide resume info
2. **System says don't resume** - `.shouldResume = false` in interruption options
3. **Audio session reactivation failed** - Can't restart the audio engine

**Important:** Recording is **already discarded** before this callback is invoked.

### Best Practices

#### 1. Always Set the Callback

```swift
await recorder.setOnUnrecoverableInterruption { [weak self] in
    await MainActor.run {
        self?.isRecording = false
        self?.showAlert = true
    }
}
```

#### 2. Don't Try to Resume

```swift
// ‚ùå Don't do this
await recorder.resumeRecording()  // Won't work!

// ‚úÖ Do this instead
try await recorder.startRecording()  // Start fresh
```

#### 3. Clean Up Resources

```swift
await recorder.setOnUnrecoverableInterruption { [weak self] in
    self?.recordingTask?.cancel()
    await MainActor.run {
        self?.isRecording = false
    }
}
```

---

## üöÄ Performance

### Accelerate Framework Integration

ACCAudioRecorder uses Apple's **Accelerate framework** for vectorized SIMD operations, providing **10-100x faster** audio processing compared to manual loops.

#### dB Calculation Performance

At **44.1kHz** with **4096** buffer size:
- ~10.7 buffers per second
- Accelerate: ~1-5 microseconds per buffer
- Manual loop: ~50-100 microseconds per buffer
- Saves **0.5-1ms** of CPU time per second
- Lower battery drain and reduced heat generation

---

## üéØ Architecture

### Broadcast Pattern

ACCAudioRecorder uses a custom `RecordingBroadcast` class that allows multiple independent subscribers to observe the same recording session:

- ‚úÖ Multiple views can observe the same recording
- ‚úÖ Each call to `getCurrentStreams()` creates new stream subscriptions
- ‚úÖ Streams are automatically cleaned up when recording ends
- ‚úÖ Thread-safe with `OSAllocatedUnfairLock`

### Actor Isolation

All recording operations are actor-isolated for thread safety:
- No race conditions
- No data races
- Proper Swift 6 strict concurrency support

### Why AVAudioEngine over AVAudioRecorder?

| Feature | AVAudioRecorder | AVAudioEngine (ACCAudioRecorder) |
|---------|----------------|----------------------------------|
| Real-time buffer access | ‚ùå | ‚úÖ |
| Audio effects | ‚ùå | ‚úÖ |
| Multiple consumers | ‚ùå | ‚úÖ |
| Network streaming | ‚ùå | ‚úÖ |
| Custom processing | ‚ùå | ‚úÖ |
| Accelerate optimization | ‚ùå | ‚úÖ |
| Actor isolation | ‚ùå | ‚úÖ |

---

## üîß Error Handling

```swift
enum ACCAudioRecorderError: Error {
    case recordingAlreadyInProgress
    case noActiveRecording
    case audioFormatCreationFailed
    case audioEngineStartFailed
}

// Handle errors
do {
    let streams = try await recorder.startRecording()
    // ...
} catch ACCAudioRecorderError.recordingAlreadyInProgress {
    print("Already recording!")
} catch {
    print("Error: \(error.localizedDescription)")
}
```

---

## üéØ Best Practices

### 1. Always Handle the Streams in Tasks

```swift
let streams = try await recorder.startRecording()
Task {
    for await buffer in streams.buffers {
        // Process buffer
    }
}
```

### 2. Remember to Call finishRecording()

```swift
await recorder.finishRecording()  // This completes all streams
```

### 3. Use Multiple Tasks for Multiple Consumers

```swift
Task { /* save to file */ }
Task { /* transcribe */ }
Task { /* visualize */ }
```

### 4. Monitor Streams on MainActor for UI Updates

```swift
Task { @MainActor in
    for await history in streams.audioLevelHistory {
        updateUI(history.last ?? -160.0)
    }
}
```

### 5. Clean Up Properly in deinit

```swift
deinit {
    bufferTask?.cancel()
    historyTask?.cancel()
    stateTask?.cancel()
}
```

---

## üôè Credits

Built with:
- **AVFoundation** - Apple's audio framework
- **Accelerate** - Apple's SIMD optimization framework
- **Swift Concurrency** - Actors and AsyncStream
- **os** - Apple's unified logging system

---

## üìù License

MIT License - see [LICENSE](LICENSE) file for details.
